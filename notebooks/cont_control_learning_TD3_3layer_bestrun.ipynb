{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Directories"
      ],
      "metadata": {
        "id": "l8Pk2GDiu4Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "mode = -1\n",
        "mode = 'local'\n",
        "# Install necessary files and create necessary folders (Only when ran in Google Drive)\n",
        "!pip install snntorch==0.5.3\n",
        "!pip install gym==0.25.2\n",
        "!pip install box2d-py==2.3.5\n",
        "!pip install torch==1.12.1+cu113\n",
        "!pip install \n",
        "!pip install swig\n",
        "!pip install gym\n",
        "!pip install gym[box2d]\n",
        "#!pip install gym[box2d]\n",
        "!mkdir tmp\n",
        "!mkdir logs\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!cp \"/content/drive/MyDrive/Colab Notebooks/dict9 LIF\" \"/content/tmp/\"\n",
        "mode = 'colab'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: snntorch==0.5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.5.3)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snntorch==0.5.3) (1.21.6)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snntorch==0.5.3) (1.1.5)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snntorch==0.5.3) (3.2.1)\nRequirement already satisfied: torch>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from snntorch==0.5.3) (1.12.0)\nRequirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->snntorch==0.5.3) (2022.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->snntorch==0.5.3) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->snntorch==0.5.3) (0.11.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->snntorch==0.5.3) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->snntorch==0.5.3) (1.4.4)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.1.0->snntorch==0.5.3) (4.4.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->snntorch==0.5.3) (1.16.0)\nRequirement already satisfied: gym==0.25.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.25.2)\nRequirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym==0.25.2) (4.13.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym==0.25.2) (1.6.0)\nRequirement already satisfied: gym-notices>=0.0.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym==0.25.2) (0.0.8)\nRequirement already satisfied: numpy>=1.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym==0.25.2) (1.21.6)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym==0.25.2) (3.9.0)\nRequirement already satisfied: box2d-py==2.3.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.3.5)\n\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.1+cu113 (from versions: 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0)\u001b[0m\n\u001b[31mERROR: No matching distribution found for torch==1.12.1+cu113\u001b[0m\n\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\nRequirement already satisfied: swig in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (4.1.0)\nRequirement already satisfied: gym in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.25.2)\nRequirement already satisfied: gym-notices>=0.0.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym) (0.0.8)\nRequirement already satisfied: numpy>=1.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym) (1.21.6)\nRequirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym) (4.13.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym) (1.6.0)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym) (3.9.0)\nRequirement already satisfied: gym[box2d] in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.25.2)\nRequirement already satisfied: cloudpickle>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (1.6.0)\nRequirement already satisfied: gym-notices>=0.0.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (0.0.8)\nRequirement already satisfied: numpy>=1.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (1.21.6)\nRequirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (4.13.0)\nRequirement already satisfied: box2d-py==2.3.5; extra == \"box2d\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (2.3.5)\nRequirement already satisfied: swig==4.*; extra == \"box2d\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (4.1.0)\nRequirement already satisfied: pygame==2.1.0; extra == \"box2d\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gym[box2d]) (2.1.0)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym[box2d]) (3.9.0)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EyOhCiEu4Bk",
        "outputId": "a79af4f7-7ac2-48b3-89e1-d54288242797",
        "gather": {
          "logged": 1670310928705
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hv0oAX5su4Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "from datetime import datetime\n",
        "from collections import deque, namedtuple\n",
        "from gym import wrappers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.cuda.memory import mem_get_info\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from snntorch import surrogate\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "YaOc25LDu4Br",
        "gather": {
          "logged": 1670310930322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A small method to save plots\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=resolution)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "1W8CBfWbvZM8",
        "gather": {
          "logged": 1670310930765
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters ###"
      ],
      "metadata": {
        "id": "DtnGruUvu4Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 5e-4                   # Learning rate # lr = 0.001\n",
        "gauss_per_dim = 64\n",
        "max_episodes = 1100         # max num of episodes\n",
        "max_timesteps = 2000        # max timesteps in one episode\n",
        "num_steps = 16              # How many steps to loop in prediction\n",
        "n_rounds = 5                # Number of competitive rounds to play\n",
        "log_interval = 100          # print avg reward after interval\n",
        "random_seed = 0\n",
        "gamma = 0.99                # discount for future rewards\n",
        "batch_size = 128            # num of transitions sampled from replay buffer\n",
        "exploration_noise = 0.1\n",
        "polyak = 0.995              # target policy update parameter (1-tau)\n",
        "policy_noise = 0.2          # target policy smoothing noise\n",
        "noise_clip = 0.5\n",
        "policy_delay = 2            # delayed policy updates parameter\n",
        "start_episode = 0"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "uSJzX05Vu4B1",
        "gather": {
          "logged": 1670310931050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'BipedalWalker-v3'\n",
        "env_name_clean = env_name.lower().replace('-','_')\n",
        "filename = env_name_clean + \".png\"\n",
        "outfilename = env_name_clean + \"scoreboard.txt\"\n",
        "datename = str(datetime.now()).split('.')[0].replace(' ', '_').replace('-', '_').replace(':', '_') \n",
        "scorefigname = env_name_clean + '_' + datename + '_scores.png'\n",
        "epsfigname = env_name_clean + '_' + datename + '_eps_history.png'\n",
        "cumfigname = env_name_clean + '_' + datename + '_cumulated_reward.png'\n",
        "distfigname = env_name_clean + '_' + datename + '_distances.png'\n",
        "meandistfigname = env_name_clean + '_' + datename + '_mean_distances.png'\n",
        "model_file = './tmp/'  + env_name_clean + '_dict9'\n",
        "model_file_target = model_file + '_target'\n",
        "directory = \"./tmp/\"\n",
        "filename = \"TD3_{}_{}\".format(env_name, random_seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('Env name (clean):',env_name_clean)\n",
        "print('Datetime (clean):', datename)\n",
        "print('Output file:', outfilename)\n",
        "print('Model file:', model_file)\n",
        "print('Running training on: ', device)\n",
        "print('Environment:', mode)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Env name (clean): bipedalwalker_v3\nDatetime (clean): 2022_12_06_07_15_30\nOutput file: bipedalwalker_v3scoreboard.txt\nModel file: ./tmp/bipedalwalker_v3_dict9\nRunning training on:  cuda\nEnvironment: colab\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAqS6F-Yu4By",
        "outputId": "da0856fb-46a2-4e66-f76f-e9c876551708",
        "gather": {
          "logged": 1670310931343
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "wU6d2CLFu4B3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actor"
      ],
      "metadata": {
        "id": "dlbfSeXDSIiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, max_action):\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim, 480)\n",
        "        self.l2 = nn.Linear(480, 240)\n",
        "        self.l3 = nn.Linear(240, action_dim)\n",
        "\n",
        "        self.max_action = max_action\n",
        "\n",
        "    def forward(self, state):\n",
        "        a = F.relu(self.l1(state))\n",
        "        a = F.relu(self.l2(a))\n",
        "        a = torch.tanh(self.l3(a)) * self.max_action\n",
        "        return a"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "P_Kt1Ienp0dx",
        "gather": {
          "logged": 1670310931709
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Critic"
      ],
      "metadata": {
        "id": "J0nnEGXw8YHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, beta=0.95):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        # Initialize grad objects        \n",
        "        spike_grad1 = surrogate.fast_sigmoid()\n",
        "        spike_grad2 = surrogate.fast_sigmoid()\n",
        "        spike_grad3 = surrogate.fast_sigmoid()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(state_dim, 128)\n",
        "        self.lif1 = snn.Leaky(beta=beta, learn_threshold=False, spike_grad=spike_grad1)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.lif2 = snn.Leaky(beta=beta, learn_threshold=False, spike_grad=spike_grad2)\n",
        "\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "        self.lif3 = snn.Leaky(beta=beta, learn_beta=True, threshold=1e5, reset_mechanism=\"none\", spike_grad=spike_grad3)\n",
        "\n",
        "    def _convert_to_spikes(self, data):\n",
        "        return snn.spikegen.delta(data, threshold=0.1, padding=False, off_spike=True)\n",
        "\n",
        "    def createGauss(self, mins, maxes, numPerDim, amplMax, dims):\n",
        "        self.amplMax = amplMax\n",
        "        self.numPerDim = numPerDim\n",
        "        self.M = []\n",
        "        self.sigma = []\n",
        "        for i in range(dims):\n",
        "            M, sigma = np.linspace(mins[i], maxes[i], numPerDim, retstep=True)\n",
        "            self.M.append(M)\n",
        "            self.sigma += [sigma, ] * self.numPerDim\n",
        "        self.M = torch.tensor(np.array(self.M).reshape(-1, self.numPerDim), dtype=torch.float).to(device)\n",
        "        self.sigma = torch.tensor(np.array(self.sigma).reshape(-1, self.numPerDim), dtype=torch.float).to(device)\n",
        "\n",
        "    def gaussianCurrents(self, data):\n",
        "        x = data.unsqueeze(-1).repeat([1, 1, self.numPerDim])\n",
        "        return (torch.exp(-1 / 2 * ((x - self.M) / self.sigma) ** 2) * self.amplMax).reshape(data.shape[0], -1)\n",
        "\n",
        "    def forward(self, state, action, num_steps = 16):\n",
        "        x = torch.cat([state, action], 1)\n",
        "        x = self.gaussianCurrents(x)\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        # Record the final layer#\n",
        "        spk1_rec = []\n",
        "        mem1_rec = []\n",
        "        \n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "        \n",
        "        spk3_rec = []\n",
        "        mem3_rec = []        \n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            \n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            \n",
        "            cur3 = self.fc3(spk2)\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            spk1_rec.append(spk1)\n",
        "            mem1_rec.append(mem1)\n",
        "            \n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "            \n",
        "            spk3_rec.append(spk3)\n",
        "            mem3_rec.append(mem3)\n",
        "\n",
        "        return mem3_rec[num_steps-1]"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "9j2tGXDTqkXA",
        "gather": {
          "logged": 1670310932341
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReplayBuffer"
      ],
      "metadata": {
        "id": "eywnQwfISDqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=5e5):\n",
        "        self.buffer = []\n",
        "        self.max_size = int(max_size)\n",
        "        self.size = 0\n",
        "    \n",
        "    def add(self, transition):\n",
        "        self.size +=1\n",
        "        # transiton is tuple of (state, action, reward, next_state, done)\n",
        "        self.buffer.append(transition)\n",
        "    \n",
        "    def sample(self, batch_size):\n",
        "        # delete 1/5th of the buffer when full\n",
        "        if self.size > self.max_size:\n",
        "            del self.buffer[0:int(self.size/5)]\n",
        "            self.size = len(self.buffer)\n",
        "        \n",
        "        indexes = np.random.randint(0, len(self.buffer), size=batch_size)\n",
        "        state, action, reward, next_state, done = [], [], [], [], []\n",
        "        \n",
        "        for i in indexes:\n",
        "            s, a, r, s_, d = self.buffer[i]\n",
        "            state.append(np.array(s, copy=False))\n",
        "            action.append(np.array(a, copy=False))\n",
        "            reward.append(np.array(r, copy=False))\n",
        "            next_state.append(np.array(s_, copy=False))\n",
        "            done.append(np.array(d, copy=False))\n",
        "        \n",
        "        return np.array(state), np.array(action), np.array(reward), np.array(next_state), np.array(done)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "izTUGxP5QsoG",
        "gather": {
          "logged": 1670310937592
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "W4KED1jNSLIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TD3:\n",
        "    def __init__(self, lr, state_size, action_size, max_action, low, high, action_low, action_high, gauss_per_dim):\n",
        "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=lr)\n",
        "\n",
        "        critic_low = np.concatenate([low, action_low])         \n",
        "        critic_high = np.concatenate([high, action_high])\n",
        "        critic_input = (state_size + action_size) * gauss_per_dim\n",
        "\n",
        "        self.critic_1 = Critic(critic_input).to(device)\n",
        "        self.critic_1_target = Critic(critic_input).to(device)\n",
        "        self.critic_1_target.load_state_dict(self.critic_1.state_dict())\n",
        "        self.critic_1_optimizer = optim.Adam(self.critic_1.parameters(), lr=lr)\n",
        "        \n",
        "        self.critic_1.createGauss(critic_low, critic_high, gauss_per_dim, 1.0, state_size+action_size)\n",
        "        self.critic_1_target.createGauss(critic_low, critic_high, gauss_per_dim, 1.0, state_size+action_size)\n",
        "\n",
        "        self.critic_2 = Critic(critic_input).to(device)\n",
        "        self.critic_2_target = Critic(critic_input).to(device)\n",
        "        self.critic_2_target.load_state_dict(self.critic_2.state_dict())\n",
        "        self.critic_2_optimizer = optim.Adam(self.critic_2.parameters(), lr=lr)\n",
        "\n",
        "        self.critic_2.createGauss(critic_low, critic_high, gauss_per_dim, 1.0, state_size+action_size)\n",
        "        self.critic_2_target.createGauss(critic_low, critic_high, gauss_per_dim, 1.0, state_size+action_size)\n",
        "\n",
        "        self.max_action = max_action\n",
        "    \n",
        "    def select_action(self, state):\n",
        "        state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
        "        return self.actor(state).cpu().data.numpy().flatten()\n",
        "    \n",
        "    def update(self, replay_buffer, n_iter, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay):\n",
        "        for i in range(n_iter):\n",
        "            # Sample a batch of transitions from replay buffer:\n",
        "            state, action_, reward, next_state, done = replay_buffer.sample(batch_size)\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            action = torch.FloatTensor(action_).to(device)\n",
        "            reward = torch.FloatTensor(reward).reshape((batch_size, 1)).to(device)\n",
        "            next_state = torch.FloatTensor(next_state).to(device)\n",
        "            done = torch.FloatTensor(done).reshape((batch_size,1)).to(device)\n",
        "            \n",
        "            # Select next action according to target policy:\n",
        "            noise = torch.FloatTensor(action_).data.normal_(0, policy_noise).to(device)\n",
        "            noise = noise.clamp(-noise_clip, noise_clip)\n",
        "            actor_target_out = self.actor_target(next_state)\n",
        "            noise = torch.reshape(noise, tuple(actor_target_out.shape))\n",
        "            next_action = (actor_target_out + noise)\n",
        "            next_action = next_action.clamp(-self.max_action, self.max_action)\n",
        "\n",
        "            # Compute target Q-value:\n",
        "            target_Q1 = self.critic_1_target(next_state, next_action)\n",
        "            target_Q2 = self.critic_2_target(next_state, next_action)\n",
        "            target_Q = torch.min(target_Q1, target_Q2)\n",
        "            target_Q = reward + ((1-done) * gamma * target_Q).detach()\n",
        "            \n",
        "            # Optimize Critic 1:\n",
        "            current_Q1 = self.critic_1(state, action)\n",
        "            loss_Q1 = F.mse_loss(current_Q1, target_Q)\n",
        "            self.critic_1_optimizer.zero_grad()\n",
        "            loss_Q1.backward()\n",
        "            self.critic_1_optimizer.step()\n",
        "            \n",
        "            # Optimize Critic 2:\n",
        "            current_Q2 = self.critic_2(state, action)\n",
        "            loss_Q2 = F.mse_loss(current_Q2, target_Q)\n",
        "            self.critic_2_optimizer.zero_grad()\n",
        "            loss_Q2.backward()\n",
        "            self.critic_2_optimizer.step()\n",
        "            \n",
        "            # Delayed policy updates:\n",
        "            if i % policy_delay == 0:\n",
        "                # Compute actor loss:\n",
        "                actor_loss = -self.critic_1(state, self.actor(state)).mean()\n",
        "                \n",
        "                # Optimize the actor\n",
        "                self.actor_optimizer.zero_grad()\n",
        "                actor_loss.backward()\n",
        "                self.actor_optimizer.step()\n",
        "                \n",
        "                # Polyak averaging update:\n",
        "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
        "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
        "                \n",
        "                for param, target_param in zip(self.critic_1.parameters(), self.critic_1_target.parameters()):\n",
        "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
        "                \n",
        "                for param, target_param in zip(self.critic_2.parameters(), self.critic_2_target.parameters()):\n",
        "                    target_param.data.copy_( (polyak * target_param.data) + ((1-polyak) * param.data))\n",
        "\n",
        "        return actor_loss.cpu().data.numpy(), loss_Q1.cpu().data.numpy(), loss_Q2.cpu().data.numpy()\n",
        "                \n",
        "    def save(self, directory, name, ep):\n",
        "        torch.save(self.actor.state_dict(), '%s/%s_actor_ep%s.pth' % (directory, name, ep))\n",
        "        torch.save(self.actor_target.state_dict(), '%s/%s_actor_target_ep%s.pth' % (directory, name, ep))\n",
        "        \n",
        "        torch.save(self.critic_1.state_dict(), '%s/%s_crtic_1_ep%s.pth' % (directory, name, ep))\n",
        "        torch.save(self.critic_1_target.state_dict(), '%s/%s_critic_1_target_ep%s.pth' % (directory, name, ep))\n",
        "        \n",
        "        torch.save(self.critic_2.state_dict(), '%s/%s_crtic_2_ep%s.pth' % (directory, name, ep))\n",
        "        torch.save(self.critic_2_target.state_dict(), '%s/%s_critic_2_target_ep%s.pth' % (directory, name, ep))\n",
        "        \n",
        "    def load(self, directory, name, ep):\n",
        "        self.actor.load_state_dict(torch.load('%s/%s_actor_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        self.actor_target.load_state_dict(torch.load('%s/%s_actor_target_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        \n",
        "        self.critic_1.load_state_dict(torch.load('%s/%s_crtic_1_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        self.critic_1_target.load_state_dict(torch.load('%s/%s_critic_1_target_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        \n",
        "        self.critic_2.load_state_dict(torch.load('%s/%s_crtic_2_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        self.critic_2_target.load_state_dict(torch.load('%s/%s_critic_2_target_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        \n",
        "    def load_actor(self, directory, name, ep):\n",
        "        self.actor.load_state_dict(torch.load('%s/%s_actor_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))\n",
        "        self.actor_target.load_state_dict(torch.load('%s/%s_actor_target_ep%s.pth' % (directory, name, ep), map_location=lambda storage, loc: storage))"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "id": "-QRt0zUKgmQB",
        "gather": {
          "logged": 1670310940853
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "g6VdDDb3NXPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gym.logger.set_level(40)\n",
        "env_name = \"BipedalWalker-v3\"\n",
        "# env_name = \"MountainCarContinuous-v0\"\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.shape[0]\n",
        "max_action = float(env.action_space.high[0])\n",
        "\n",
        "policy = TD3(lr, \n",
        "             state_dim, \n",
        "             action_dim, \n",
        "             max_action, \n",
        "             env.observation_space.low, \n",
        "             env.observation_space.high, \n",
        "             env.action_space.low, \n",
        "             env.action_space.high, \n",
        "             gauss_per_dim)\n",
        "\n",
        "replay_buffer = ReplayBuffer()\n",
        "\n",
        "# logging variables:\n",
        "scores = []\n",
        "mean_scores = []\n",
        "last_scores = deque(maxlen=log_interval)\n",
        "distances = []\n",
        "mean_distances = []\n",
        "last_distance = deque(maxlen=log_interval)\n",
        "losses_mean_episode = []"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "id": "IsvIgAee2qTB",
        "gather": {
          "logged": 1670310946298
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "Eu7TQfmXu4CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training procedure:\n",
        "for ep in range(start_episode + 1, max_episodes + 1):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    total_distance = 0\n",
        "    actor_losses = []\n",
        "    c1_losses = []\n",
        "    c2_losses = []\n",
        "\n",
        "    for t in range(max_timesteps):\n",
        "        # select action and add exploration noise:\n",
        "        action = policy.select_action(state)\n",
        "        action = action + np.random.normal(0, exploration_noise, size=action.shape[0])\n",
        "        action = action.clip(env.action_space.low, env.action_space.high)\n",
        "\n",
        "        # take action in env:\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        replay_buffer.add((state, action, reward, next_state, float(done)))\n",
        "        state = next_state\n",
        "\n",
        "        total_reward += reward\n",
        "        if reward != -100:\n",
        "            total_distance += reward\n",
        "\n",
        "        # if episode is done then update policy:\n",
        "        if done or t == (max_timesteps - 1):\n",
        "            actor_loss, c1_loss, c2_loss = policy.update(replay_buffer, t, batch_size, gamma, polyak, policy_noise, noise_clip, policy_delay)\n",
        "            actor_losses.append(actor_loss)\n",
        "            c1_losses.append((c1_loss))\n",
        "            c2_losses.append(c2_loss)\n",
        "            break\n",
        "\n",
        "    mean_loss_actor = np.mean(actor_losses)\n",
        "    mean_loss_c1 = np.mean(c1_losses)\n",
        "    mean_loss_c2 = np.mean(c2_losses)\n",
        "    losses_mean_episode.append((ep, mean_loss_actor, mean_loss_c1, mean_loss_c2))\n",
        "    print('\\rEpisode: {}/{},\\tScore: {:.2f},\\tDistance: {:.2f},\\tactor_loss: {:.2f},\\tc1_loss:{:.2f},\\tc2_loss:{:.2f}'\n",
        "        .format(ep, max_episodes,total_reward, total_distance, mean_loss_actor, mean_loss_c1, mean_loss_c2), end=\"\")\n",
        "\n",
        "    # logging updates:\n",
        "    scores.append(total_reward)\n",
        "    distances.append(total_distance)\n",
        "    last_scores.append(total_reward)\n",
        "    last_distance.append(total_distance)\n",
        "    mean_score = np.mean(last_scores)\n",
        "    mean_distance = np.mean(last_distance)\n",
        "    FILE = 'record.dat'\n",
        "    data = [ep, total_reward, total_distance, mean_loss_actor, mean_loss_c1, mean_loss_c2]\n",
        "    \n",
        "    with open(FILE, \"ab\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    # print avg reward every log interval:\n",
        "    if ep % log_interval == 0:\n",
        "        policy.save(directory, filename, str(ep))\n",
        "        mean_scores.append(mean_score)\n",
        "        mean_distances.append(mean_distance)\n",
        "        print('\\rEpisode: {}/{},\\tMean Score: {:.2f},\\tMean Distance: {:.2f},\\tactor_loss: {:.2f},\\tc1_loss:{:.2f},\\tc2_loss:{:.2f}'\n",
        "            .format(ep, max_episodes, mean_score, mean_distance, mean_loss_actor, mean_loss_c1, mean_loss_c2))\n",
        "        \n",
        "        FILE = 'record_mean.dat'\n",
        "        data = [ep, mean_score, mean_distance, mean_loss_actor, mean_loss_c1, mean_loss_c2]\n",
        "        with open(FILE, \"ab\") as f:\n",
        "            pickle.dump(data, f)\n",
        "        \n",
        "        if mean_score >= 300 and len(last_scores) == 100:\n",
        "            print(\"Solved!\")\n",
        "            name = filename + '_solved'\n",
        "            policy.save(directory, name, str(ep))\n",
        "            break\n",
        "env.close()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Episode: 100/1100,\tMean Score: -65.87,\tMean Distance: -24.87,\tactor_loss: 8.74,\tc1_loss:0.34,\tc2_loss:0.13\nEpisode: 200/1100,\tMean Score: -40.30,\tMean Distance: -29.30,\tactor_loss: 4.40,\tc1_loss:0.13,\tc2_loss:0.13\nEpisode: 300/1100,\tMean Score: -34.29,\tMean Distance: -34.29,\tactor_loss: 6.04,\tc1_loss:0.49,\tc2_loss:0.35\nEpisode: 400/1100,\tMean Score: -51.98,\tMean Distance: -48.98,\tactor_loss: 5.11,\tc1_loss:0.60,\tc2_loss:0.31\nEpisode: 500/1100,\tMean Score: -51.92,\tMean Distance: -45.92,\tactor_loss: 2.95,\tc1_loss:0.21,\tc2_loss:0.07\nEpisode: 600/1100,\tMean Score: -32.68,\tMean Distance: -31.68,\tactor_loss: 4.04,\tc1_loss:0.60,\tc2_loss:0.29\nEpisode: 700/1100,\tMean Score: -56.83,\tMean Distance: -45.83,\tactor_loss: 14.21,\tc1_loss:0.12,\tc2_loss:0.13\nEpisode: 800/1100,\tMean Score: -100.99,\tMean Distance: -98.99,\tactor_loss: 7.59,\tc1_loss:0.02,\tc2_loss:0.02\nEpisode: 900/1100,\tMean Score: -102.80,\tMean Distance: -101.80,\tactor_loss: 6.24,\tc1_loss:0.00,\tc2_loss:0.01\nEpisode: 932/1100,\tScore: -125.38,\tDistance: -125.38,\tactor_loss: 5.87,\tc1_loss:0.01,\tc2_loss:0.02\rEpisode: 938/1100,\tScore: -114.02,\tDistance: -14.02,\tactor_loss: 5.71,\tc1_loss:0.21,\tc2_loss:0.45\rEpisode: 949/1100,\tScore: -61.56,\tDistance: -61.56,\tactor_loss: 6.92,\tc1_loss:0.36,\tc2_loss:1.37"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Bad pipe message: %s [b'\\xaaSW']\nBad pipe message: %s [b'a\\x05\\xdc\\x92\\xd6\\xb8\\x85Ps\\x06\\\\\\x82h\\x1b\\xaf\\xc3\\x16\\x92 \\xbc\\xbf\\xbeF\\x8e\\xbbEdb\\x14[', b'EkU\\x97\\xa3]\\x89\\xf7\\xd8\\xc0\\xa9\\x10\\x0f\\x08\\x00\\x8c\\xbeX\\xbd\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08', b'\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01']\nBad pipe message: %s [b'\\xd8\\xf08\\xda{q\\t\\xc9\\x88\\x8d\\xf3\\xd1\\xe5 \\x81*n\\xfb\\xc4\\xdf\\x8b{Y\\xcb\\x80g\\xe1 \\x97\\xba|\\xc35x{\\x9849G\\xda?o>\\xbav\\xda\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08', b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\nBad pipe message: %s [b'']\nBad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 )S\\xdf\\xf2X\\x92o\\xea\\x85W\\x98j\\xdao\\xca\\xd0\\x06\\x8a\\xa1\\x13\\x1di']\nBad pipe message: %s [b\"\\x85P\\xea\\x9a{\\xb1\\x03o\\xb5\\xbb\\xf4\\xba\\xd0\\xf4lr::\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\"]\nBad pipe message: %s [b'\\x15\\xdd\\xb6\\x87\\xae\\x90\\xca\\xee\\xa9\\xad\\xab\\xee\\xb9\\xa0,\\xe8\\xc7\\xe3\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#']\nBad pipe message: %s [b'\\x90T\\x17-e\\x07\\xf9f\\\\\\xf4\\xaa\\x87\\x8e\\xf5\\x88\\xb4iW\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12']\nBad pipe message: %s [b'\\xe2\\x8ccHI\"6\\xddU\\xb3K\\x81\\x8f!9\\xd9F)\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0\\'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x00']\nBad pipe message: %s [b'0\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00']\nBad pipe message: %s [b\"l\\x18\\x12U\\xe5\\xa1\\x1f\\xa5TU\\x1b\\xb5?\\x93\\x97\\xdd@\\xf4\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\"]\nBad pipe message: %s [b'a)\\x89\\xd1k\\xb9\\x1d\\x0b\\x0f\\x86l\\x8a\\x1b\\xb7\\xe6\\xd0\\xf87 \\xcc\\xe0~?P\\xdc\\xd7\\xbb\\x85\\x91\\x99/\\x94\\xc0\\xa7\\xeb\\xc0\\xfe4\"(\\xbf\\xc6\\xf7\\xfc\\xc6\\x02\\xa1V4\\xfey\\x00\\x08']\nBad pipe message: %s [b'\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00']\nBad pipe message: %s [b\"\\xa9\\xa2K\\x08\\x81+\\xa0\\xe6*\\xde{\\x88\\xc8+\\xc7\\xf5\\xd9\\x1f\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\", b'\\n']\nBad pipe message: %s [b\"r\\xf7\\xea\\xdd\\xd7~\\xe8,7\\xa7CfkX\\x8c\\xbf\\t\\xe3\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\", b'\\x06\\x03\\x08\\x07', b'\\x08\\t\\x08\\n\\x08\\x0b\\x08']\nBad pipe message: %s [b'\\x05\\x08\\x06']\nBad pipe message: %s [b'\\x05\\x01\\x06', b'', b'\\x03\\x03']\nBad pipe message: %s [b'']\nBad pipe message: %s [b'', b'\\x02']\nBad pipe message: %s [b'u\\xce\\xb6f\\x9f\\x02\\xe6\\xd8\\xdd%lq\\x81\\xfbA`\\xbb\\xb6\\x00\\x00>\\xc0\\x14\\xc0\\n\\x00', b'8\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b'']\nBad pipe message: %s [b'\\x93\\xb3\\xc8<\\xe9P\\xe6\\xdbFE_\\xe1\\x82\\x1e2\\x18\\x00\\x99\\x00\\x00']\nBad pipe message: %s [b'\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff']\nBad pipe message: %s [b'\\xa9Z\\xca\\x94\\xa822\\xcf\\x890A\\x97\\xda\\xc8C\\x04\\x9a\\xeb\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a']\nBad pipe message: %s [b'1\\x7f+\\x81\\x9dE\\xf3\\x97\\x92TZ\\xc6\\xec\\xbc\\xa1\\xe1-\\n\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00']\nBad pipe message: %s [b'\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01']\nBad pipe message: %s [b'\\xa1}vf\\xd8\"\\xc9\\xe7\\xca9-c\\xaaS\\x0b\\xa2fS']\nBad pipe message: %s [b'\\xaf\\xfc\\xdd\\x1b\\xc8@\\x16\\xb2\\x927\\xb4\\x84\\xc1\\x1b\\xecm\\x88\\x13\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00']\nBad pipe message: %s [b'\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b']\nBad pipe message: %s [b\"\\xc1\\xaa\\xed'\\x1e\\x06\\xb1$\\xfaVyVq\\xd2\\xb3Z>\\xdf\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\"]\nBad pipe message: %s [b'\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02']\nBad pipe message: %s [b'']\nBad pipe message: %s [b\"\\x90z\\xac\\xf7Bh(\\x89\\x81(\\x1egSn\\xc8\\x9d\\x98\\x9d\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00\"]\nBad pipe message: %s [b'\\x03']\nBad pipe message: %s [b'/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14']\nBad pipe message: %s [b'`L\\x83\\xb9pq\\xa2\\xae\\x98\\x87;_x\\xab9\\x1c\\x07\\xc9 \\xfc\\xcc\\xa1Ma\\t\\x128\\x80\\xc1\\xe7\\xd9C\\xff\\xcf\\x99)\\xc4\\xa9\\xb6\\x0b\\x0f\\xa7\\xba\\xebB\\xad\\x88\\x0fP\\xa1\\xa8\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 B)DtU\\xc7S\\xe27\\x1fT']\nBad pipe message: %s [b'\\x05\\xcbN\\x1b\\x15\\xc6\\xc7\\xbf\\x19\\xb1\\xa5\\xbbY']\nBad pipe message: %s [b'\\xdb\\x11\\xd5\\x0b\\x03\\xb9\\xd6\\xdd\\xd3\\xf3\\xe8\\xfa\\x1bnS\\x8d\\x84\\x97\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00']\nBad pipe message: %s [b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\nBad pipe message: %s [b'\\x02\\x1f\\xa1\\xfd\\xb1\\x82\\x80z\\xbdti\\xab\\x02\\x1e\\x088Y\\xa6\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00']\nBad pipe message: %s [b'A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00']\nBad pipe message: %s [b'\\xce\\xee\\x82W\\xb3\\xc4Qg\\xb4T\\x9bW\\xa4\\x1d\"B?\\xad\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0', b'\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x15\\x03']\nBad pipe message: %s [b\"\\xbd\\x87R\\xa7th\\x06\\xbc\\xf8\\xcd\\xd5WL]\\xa3\\xfcS\\x90\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\"]\nBad pipe message: %s [b'\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00']\nBad pipe message: %s [b'@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b']\nBad pipe message: %s [b'\\xa5\\xee`hv\\xc56\\x87\\xbc\\xbc\\xf6\\xc29\\x03CF\\x04\" ;\\xb1\\xee4\\xbc\\xe4\\x94b<\\xd7\\xb1\\x16\\x11Am\\xfc\\x180\\xdc\\xff3\\xed\\xa3\\x91\\x1f\\xcfY\\x90\\xd7\\xabY\"\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08', b'\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01']\nBad pipe message: %s [b\"\\x81\\xb9Zz\\xe4a\\x99\\xd6\\xd3\\xc5\\xda\\x98+A1\\xc7\\xfd?\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\"]\nBad pipe message: %s [b'\\xcc\\xcfx\\xbd\\xad\\xd1N\\xe2v\\x81\\x1ep\\xd6\\xad\\x80\\xfc\\xc3\\xbc\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j', b\"\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\", b'']\nBad pipe message: %s [b'', b'\\x03\\x03']\nBad pipe message: %s [b'']\nBad pipe message: %s [b'', b'\\x02']\nBad pipe message: %s [b'\\x05\\x02\\x06']\nBad pipe message: %s [b'\\xff\\xeb\\x85\\xf6\\x02k\\xfd\\xc3\\xf0\\x91\\xaex\\x8a\\xb2\\xac\\xd8\\xbe\\xe2\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0']\nBad pipe message: %s [b'\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00']\nBad pipe message: %s [b'D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00']\nBad pipe message: %s [b'\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00']\nBad pipe message: %s [b'\\x17\\x00\\x03\\xc0\\x10']\nBad pipe message: %s [b'']\nBad pipe message: %s [b'\\xc9\\xcb\\xb0\\x93\\r F\\x8c\\x8e\\xea\"66\\xb2~tF?\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0']"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnqogd1cV8B",
        "outputId": "5d32b63d-9c31-42ae-a124-b4753ade4a62",
        "gather": {
          "logged": 1670256454665
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "aoRFdJH1u4CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [idx + 1 for idx in range(len(scores))]\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(x, scores)\n",
        "plt.title('Scores [' + env_name + ']')\n",
        "plt.grid()\n",
        "save_fig(scorefigname)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "NXe3NShru4CD",
        "gather": {
          "logged": 1670256454933
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_reward = np.cumsum(scores)\n",
        "c_indices = np.arange(len(c_reward))\n",
        "rolling_avg = c_reward / c_indices\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(x, rolling_avg)\n",
        "plt.title('Average reward [' + env_name + ']')\n",
        "plt.grid()\n",
        "save_fig(cumfigname)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "y4tPHG0saO2D",
        "gather": {
          "logged": 1670256454955
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(np.arange(len(distances)), distances)\n",
        "plt.title('Distances [' + env_name + ']')\n",
        "plt.grid()\n",
        "save_fig(distfigname)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "hs-oS5UrE8sQ",
        "gather": {
          "logged": 1670256454977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_distances = np.cumsum(distances)\n",
        "c_indices_distances = np.arange(len(c_distances))\n",
        "rolling_avg_distances = c_distances / c_indices_distances\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(x, rolling_avg_distances)\n",
        "plt.title('Mean distance [' + env_name + ']')\n",
        "plt.grid()\n",
        "save_fig(meandistfigname)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "a3NPuueUFRPI",
        "gather": {
          "logged": 1670256455003
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log"
      ],
      "metadata": {
        "id": "aHnAgjMGu4CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfname = datename + '_runlogs'\n",
        "df_avg_path = 'logs/' + env_name_clean + '_' + dfname + '_avg.csv'\n",
        "df_dist_path = 'logs/' + env_name_clean + '_' + dfname + '_distances.csv'\n",
        "\n",
        "df_avg = pd.DataFrame({'avg_score': rolling_avg})\n",
        "df_dist = pd.DataFrame({'distances': distances})\n",
        "\n",
        "df_avg.to_csv(df_avg_path, sep = ';', header = True, index = False)\n",
        "df_dist.to_csv(df_dist_path, sep = ';', header = True, index = False)\n",
        "\n",
        "print(\"Done logging results\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "UU1BATVPu4CF",
        "gather": {
          "logged": 1670256455025
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "76pGlcaiu4CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compscores = 0\n",
        "for i in range(n_rounds):\n",
        "    done = False\n",
        "    state = env.reset()\n",
        "    score = 0\n",
        "\n",
        "    while not done:\n",
        "        env.render()\n",
        "        \n",
        "        action = policy.select_action(state)\n",
        "        \n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        replay_buffer.add((state, action, reward, next_state, float(done)))\n",
        "        \n",
        "        state = next_state\n",
        "        score += reward\n",
        "    \n",
        "    compscores += score\n",
        "    print(\"Competitive round \", i + 1, \" Overall score \", compscores)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "vjCoTRAtu4CI",
        "gather": {
          "logged": 1670256455047
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Score"
      ],
      "metadata": {
        "id": "Lzg3fZnYu4CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(outfilename, \"w\") as f:\n",
        "    f.writelines(\"%s: %i\\n\" % (env_name_clean, compscores))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "kdr_4ZppOJs3",
        "gather": {
          "logged": 1670256455070
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if(mode == 'colab'):\n",
        "    from google.colab import files\n",
        "    files.download(model_file)\n",
        "    files.download(model_file_target)\n",
        "    files.download(outfilename)\n",
        "    files.download(df_avg_path)\n",
        "    files.download(df_dist_path)\n",
        "    files.download('images/' + scorefigname)\n",
        "    files.download('images/' + cumfigname)\n",
        "    files.download('images/' + distfigname)\n",
        "    files.download('images/' + meandistfigname)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "SqaiDFmKOJWg",
        "gather": {
          "logged": 1670256455099
        }
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}